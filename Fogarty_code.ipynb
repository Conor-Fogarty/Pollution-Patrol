{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d733a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b564b9be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class AirQualityDB:\n",
    "    def __init__(self, db_name: str = \"air_quality.db\"):\n",
    "        #Initilizes database and creates tables if they don't exist using below function\n",
    "        self.conn = sqlite3.connect(db_name)\n",
    "        self.create_tables()\n",
    "    \n",
    "    def create_tables(self):\n",
    "        with self.conn:\n",
    "            # Create locations table\n",
    "            self.conn.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS locations (\n",
    "                    location_id INTEGER PRIMARY KEY,\n",
    "                    city TEXT,\n",
    "                    name TEXT,\n",
    "                    latitude REAL,\n",
    "                    longitude REAL\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            # Create measurements table\n",
    "            self.conn.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS measurements (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    location_id INTEGER,\n",
    "                    parameter TEXT,\n",
    "                    value REAL,\n",
    "                    unit TEXT,\n",
    "                    timestamp DATETIME,\n",
    "                    latitude REAL,\n",
    "                    longitude REAL,\n",
    "                    FOREIGN KEY (location_id) REFERENCES locations (location_id)\n",
    "                )\n",
    "            \"\"\")\n",
    "    \n",
    "    def insert_location(self, location_id: int, city: str, name: str, latitude: float, longitude: float):\n",
    "        #Insert/Update Locations into SQl db\n",
    "        with self.conn:\n",
    "                self.conn.execute(\"\"\"\n",
    "                    INSERT OR REPLACE INTO locations \n",
    "                    (location_id, city, name, latitude, longitude)\n",
    "                    VALUES (?, ?, ?, ?, ?)\n",
    "                \"\"\", (location_id, city, name, latitude, longitude))\n",
    "    \n",
    "    def insert_measurements(self, measurements: List[Dict]):\n",
    "        #Inserts measurements, include locationID, paramters with their respective values and units, date and time, and coordinates\\s \n",
    "        with self.conn:\n",
    "            for measurement in measurements:\n",
    "                    self.conn.execute(\"\"\"\n",
    "                        INSERT INTO measurements \n",
    "                        (location_id, parameter, value, unit, timestamp, latitude, longitude)\n",
    "                        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "                    \"\"\", (\n",
    "                        measurement.get('locationId'),\n",
    "                        measurement.get('parameter'),\n",
    "                        measurement.get('value'),\n",
    "                        measurement.get('unit'),\n",
    "                        measurement.get('date', {}).get('utc'),\n",
    "                        measurement.get('coordinates', {}).get('latitude'),\n",
    "                        measurement.get('coordinates', {}).get('longitude')\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f11570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_measurements(location_id: int, api_key: str, \n",
    "                      date_from: Optional[str] = None,\n",
    "                      date_to: Optional[str] = None,\n",
    "                      parameter: Optional[str] = None) -> Optional[Dict]:\n",
    "    #Fetch mehtod accessing the OpenAQ API, fetches the raw JSON data from the API and parses into a python dictonary \n",
    "    base_url = \"https://api.openaq.org/v2/measurements\"\n",
    "    \n",
    "    params = {\n",
    "        \"location_id\": location_id,\n",
    "        \"limit\": 1000,\n",
    "        \"date_from\": date_from or (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\"),\n",
    "        \"date_to\": date_to or datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    }\n",
    "    \n",
    "    if parameter:\n",
    "        params[\"parameter\"] = parameter\n",
    "    \n",
    "    headers = {\"X-API-Key\": api_key}\n",
    "    \n",
    "    response = requests.get(base_url, params=params, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    print(\"Failed to fetch data!\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed9d358",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class AirQualityAnalyzer:\n",
    "    def __init__(self, db_connection: sqlite3.Connection):\n",
    "        self.conn = db_connection\n",
    "\n",
    "    def get_pm25_extremes(self, city: str) -> pd.DataFrame:\n",
    "        #Queries on the given city, return in a daily avg, daily min, and daily max, then utilizes rank to order by average values ASC, and order by average values DSC  \n",
    "        query = \"\"\"\n",
    "            SELECT \n",
    "                l.name as location_name,\n",
    "                DATE(m.timestamp) as date,\n",
    "                AVG(m.value) as daily_avg,\n",
    "                MIN(m.value) as daily_min,\n",
    "                MAX(m.value) as daily_max,\n",
    "                RANK() OVER (PARTITION BY l.name ORDER BY AVG(m.value) DESC) as highest_rank,\n",
    "                RANK() OVER (PARTITION BY l.name ORDER BY AVG(m.value) ASC) as lowest_rank\n",
    "            FROM measurements m\n",
    "            JOIN locations l ON m.location_id = l.location_id\n",
    "            WHERE m.parameter = 'pm25' \n",
    "            AND l.city = ?\n",
    "            GROUP BY l.name, DATE(m.timestamp)\n",
    "            ORDER BY l.name, date\n",
    "        \"\"\"\n",
    "        return pd.read_sql_query(query, self.conn, params=(city,))\n",
    "\n",
    "    def get_city_pm25_trends(self, city: str) -> pd.DataFrame:\n",
    "        #Returns measurement values ordered by timestampe, this is utilized for time-wise plotting \n",
    "        query = \"\"\"\n",
    "            SELECT \n",
    "                m.timestamp,\n",
    "                m.value,\n",
    "                l.name as location_name\n",
    "            FROM measurements m\n",
    "            JOIN locations l ON m.location_id = l.location_id\n",
    "            WHERE m.parameter = 'pm25'\n",
    "            AND l.city = ?\n",
    "            ORDER BY m.timestamp\n",
    "        \"\"\"\n",
    "        return pd.read_sql_query(query, self.conn, params=(city,))\n",
    "\n",
    "    def plot_city_pm25_trends(self, city: str):\n",
    "        #Calls get_city_pm25_trends and plots trends over time for all locations in a city \n",
    "        data = self.get_city_pm25_trends(city)\n",
    "        if data.empty:\n",
    "            print(f\"No PM2.5 data found for {city}\")\n",
    "            return None\n",
    "            \n",
    "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "        \n",
    "        plt.figure(figsize=(15, 7))\n",
    "        \n",
    "        # Plot each location with a different color\n",
    "        for location in data['location_name'].unique():\n",
    "            location_data = data[data['location_name'] == location]\n",
    "            if not location_data.empty:\n",
    "                plt.plot(location_data['timestamp'], location_data['value'], \n",
    "                        alpha=0.4, label=f'{location} (Raw)')\n",
    "                \n",
    "                # Add rolling average\n",
    "                rolling_mean = location_data['value'].rolling(window=24).mean()\n",
    "                plt.plot(location_data['timestamp'], rolling_mean, \n",
    "                        alpha=1.0, label=f'{location} (24h Avg)')\n",
    "        \n",
    "        plt.title(f'PM2.5 Trends in {city}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('PM2.5 (µg/m³)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "\n",
    "    def compare_ozone_levels(self, city1: str, city2: str) -> pd.DataFrame:\n",
    "        #Compares daily average ozone levels between two cities\n",
    "        query = \"\"\"\n",
    "            SELECT \n",
    "                m1.date,\n",
    "                m1.daily_avg_o3 as city1_o3,\n",
    "                m2.daily_avg_o3 as city2_o3\n",
    "            FROM (\n",
    "                SELECT \n",
    "                    DATE(m.timestamp) as date,\n",
    "                    AVG(m.value) as daily_avg_o3\n",
    "                FROM measurements m\n",
    "                JOIN locations l ON m.location_id = l.location_id\n",
    "                WHERE m.parameter = 'o3' AND l.city = ?\n",
    "                GROUP BY DATE(m.timestamp)\n",
    "            ) m1\n",
    "            LEFT JOIN (\n",
    "                SELECT \n",
    "                    DATE(m.timestamp) as date,\n",
    "                    AVG(m.value) as daily_avg_o3\n",
    "                FROM measurements m\n",
    "                JOIN locations l ON m.location_id = l.location_id\n",
    "                WHERE m.parameter = 'o3' AND l.city = ?\n",
    "                GROUP BY DATE(m.timestamp)\n",
    "            ) m2 ON m1.date = m2.date\n",
    "            ORDER BY m1.date\n",
    "    \"\"\"\n",
    "        return pd.read_sql_query(query, self.conn, params=(city1, city2))\n",
    "\n",
    "    def get_city_ozone_levels(self, city: str) -> pd.DataFrame:\n",
    "        #Gets ozone levels for each loction within a city, ie NYC(Manhattan, Brooklyn, Queens)\n",
    "        query = \"\"\"\n",
    "            SELECT \n",
    "                l.name as location_name,\n",
    "                DATE(m.timestamp) as date,\n",
    "                AVG(m.value) as daily_avg_o3\n",
    "            FROM measurements m\n",
    "            JOIN locations l ON m.location_id = l.location_id\n",
    "            WHERE m.parameter = 'o3'\n",
    "            AND l.city = ?\n",
    "            GROUP BY l.name, DATE(m.timestamp)\n",
    "            ORDER BY l.name, date\n",
    "        \"\"\"\n",
    "        return pd.read_sql_query(query, self.conn, params=(city,))\n",
    "\n",
    "    def plot_cities_ozone_comparison(self, city1: str, city2: str):\n",
    "        #plots comparison made in above function \n",
    "        data = self.compare_ozone_levels(city1, city2)\n",
    "        if data.empty:\n",
    "            print(f\"No ozone data found for comparison between {city1} and {city2}\")\n",
    "            return None\n",
    "            \n",
    "        plt.figure(figsize=(15, 7))\n",
    "        \n",
    "        plt.plot(data['date'], data['city1_o3'], \n",
    "                alpha=0.6, label=f'{city1} Average', linewidth=2)\n",
    "        plt.plot(data['date'], data['city2_o3'], \n",
    "                alpha=0.6, label=f'{city2} Average', linewidth=2)\n",
    "        \n",
    "        plt.title(f'Ozone Level Comparison: {city1} vs {city2}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('O₃ (ppb)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c52ba3d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    api_key = \"4557293704f9ea4cfe0e78910aec656f78e52cf707dc5728c677556cccb785ac\"\n",
    "    \n",
    "    city_locations = {\n",
    "        \"NewYork\": [\n",
    "            (625, \"New York - Manhattan\"),\n",
    "            (648, \"New York - Brooklyn\"),\n",
    "            (631, \"New York - Queens\")\n",
    "        ],\n",
    "        #Boston required 2 more additions over New York due to either measurements not being recorded which they were stated to record or machine malfunction, only Roxbury, Fort Hill and Chinatown truly recorded PM2.5 levels \n",
    "        \"Boston\": [\n",
    "            (384, \"Boston - Chinatown\"),\n",
    "            (521, \"Boston - Kenmore\"),\n",
    "            (448, \"Boston - Roxbury\"),\n",
    "            (452, \"Boston - Von Hillern\"),\n",
    "            (2117520, \"Boston- Roxbury, Fort Hill\")\n",
    "        ]\n",
    "    }\n",
    "    # Initialize database and fectch data for the past month \n",
    "    db = AirQualityDB()\n",
    "    date_from = \"2024-11-16\"\n",
    "    date_to = \"2024-12-16\"\n",
    "    print(f\"Fetching data from {date_from} to {date_to}\")\n",
    "    \n",
    "    # store the fetched data for each city and location combo \n",
    "    for city, locations in city_locations.items():\n",
    "        print(f\"\\nProcessing {city} locations:\")\n",
    "        for location_id, location_name in locations:\n",
    "            print(f\"Fetching data for {location_name} (ID: {location_id})\")\n",
    "            \n",
    "            data = fetch_measurements(\n",
    "                location_id,\n",
    "                api_key,\n",
    "                date_from=date_from,\n",
    "                date_to=date_to\n",
    "            )\n",
    "            \n",
    "            if data and 'results' in data:\n",
    "                print(f\"Found {len(data['results'])} measurements\")\n",
    "                \n",
    "                # Store location metadata\n",
    "                first_result = data['results'][0] if data['results'] else None\n",
    "                if first_result:\n",
    "                    coords = first_result.get('coordinates', {})\n",
    "                    db.insert_location(\n",
    "                        location_id,\n",
    "                        city,\n",
    "                        location_name,\n",
    "                        coords.get('latitude'),\n",
    "                        coords.get('longitude')\n",
    "                    )\n",
    "                \n",
    "                # Store measurements using the insert_measurements function \n",
    "                db.insert_measurements(data['results'])\n",
    "            else:\n",
    "                print(f\"No data found or error in API response\")\n",
    "    \n",
    "    # Initialize analyzer from class AirQualityAnalyzer\n",
    "    analyzer = AirQualityAnalyzer(db.conn)\n",
    "    \n",
    "    # Try to create and save the plot\n",
    "    for city in city_locations.keys():\n",
    "        print(f\"\\nAnalyzing {city} data:\")\n",
    "            \n",
    "        # Get PM2.5 extremes\n",
    "        pm25_extremes = analyzer.get_pm25_extremes(city)\n",
    "        if not pm25_extremes.empty:\n",
    "            print(f\"\\nPM2.5 Extreme Periods in {city}:\")\n",
    "            print(\"\\nHighest PM2.5 Days:\")\n",
    "            print(pm25_extremes.nsmallest(5, 'highest_rank')[['date', 'daily_avg']])\n",
    "            print(\"\\nLowest PM2.5 Days:\")\n",
    "            print(pm25_extremes.nsmallest(5, 'lowest_rank')[['date', 'daily_avg']])\n",
    "            \n",
    "        # Generate PM2.5 trends plot\n",
    "        pm25_plot = analyzer.plot_city_pm25_trends(city)\n",
    "        if pm25_plot:\n",
    "            pm25_plot.savefig(f'{city.lower()}_pm25_trends.png', bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "    # Compare ozone levels between cities\n",
    "    ozone_plot = analyzer.plot_cities_ozone_comparison(\"NewYork\", \"Boston\")\n",
    "    if ozone_plot:\n",
    "        ozone_plot.savefig('ozone_cities_comparison.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    db.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0af0b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2024-11-16 to 2024-12-16\n",
      "\n",
      "Processing NewYork locations:\n",
      "Fetching data for New York - Manhattan (ID: 625)\n",
      "Found 717 measurements\n",
      "Fetching data for New York - Brooklyn (ID: 648)\n",
      "Found 638 measurements\n",
      "Fetching data for New York - Queens (ID: 631)\n",
      "Found 1000 measurements\n",
      "\n",
      "Processing Boston locations:\n",
      "Fetching data for Boston - Chinatown (ID: 384)\n",
      "Found 1000 measurements\n",
      "Fetching data for Boston - Kenmore (ID: 521)\n",
      "Found 1000 measurements\n",
      "Fetching data for Boston - Roxbury (ID: 448)\n",
      "Found 1000 measurements\n",
      "Fetching data for Boston - Von Hillern (ID: 452)\n",
      "Found 1000 measurements\n",
      "Fetching data for Boston- Roxbury, Fort Hill (ID: 2117520)\n",
      "Found 1000 measurements\n",
      "\n",
      "Analyzing NewYork data:\n",
      "\n",
      "PM2.5 Extreme Periods in NewYork:\n",
      "\n",
      "Highest PM2.5 Days:\n",
      "          date  daily_avg\n",
      "21  2024-12-10  19.537500\n",
      "29  2024-11-17  13.308333\n",
      "67  2024-12-10  14.541667\n",
      "20  2024-12-09  12.166667\n",
      "51  2024-12-09  13.258333\n",
      "\n",
      "Lowest PM2.5 Days:\n",
      "          date  daily_avg\n",
      "8   2024-11-24   2.141667\n",
      "33  2024-11-21   3.025000\n",
      "63  2024-12-06   2.537500\n",
      "6   2024-11-22   2.570833\n",
      "34  2024-11-22   3.366667\n",
      "\n",
      "Analyzing Boston data:\n",
      "\n",
      "PM2.5 Extreme Periods in Boston:\n",
      "\n",
      "Highest PM2.5 Days:\n",
      "          date  daily_avg\n",
      "6   2024-12-10  13.950000\n",
      "43  2024-12-16  12.021204\n",
      "5   2024-12-09  12.725000\n",
      "25  2024-11-28  11.169039\n",
      "1   2024-12-05   8.450000\n",
      "\n",
      "Lowest PM2.5 Days:\n",
      "          date  daily_avg\n",
      "2   2024-12-06   2.487500\n",
      "22  2024-11-25   0.288921\n",
      "12  2024-12-16   4.000000\n",
      "21  2024-11-24   0.338093\n",
      "10  2024-12-14   4.487500\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
